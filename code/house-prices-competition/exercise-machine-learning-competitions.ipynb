{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Introduction\n","\n","In this exercise, you will create and submit predictions for a Kaggle competition. You can then improve your model (e.g. by adding features) to apply what you've learned and move up the leaderboard.\n","\n","Begin by running the code cell below to set up code checking and the filepaths for the dataset."]},{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2022-02-08T20:47:40.242735Z","iopub.status.busy":"2022-02-08T20:47:40.241858Z","iopub.status.idle":"2022-02-08T20:47:40.30044Z","shell.execute_reply":"2022-02-08T20:47:40.299787Z","shell.execute_reply.started":"2022-02-08T20:47:40.242605Z"},"trusted":true},"outputs":[],"source":["# Set up code checking\n","# Set up filepaths\n","import os\n","os.chdir(os.path.join(os.path.expanduser('~'), 'kaggle'))"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[],"source":["# Import helpful libraries\n","import numpy as np\n","import pandas as pd\n","from pandas.api.types import is_string_dtype, is_numeric_dtype\n","\n","from sklearn.ensemble import RandomForestRegressor\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import OneHotEncoder"]},{"cell_type":"markdown","metadata":{},"source":["## Load data to pd.Df"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[],"source":["iowa_file_path = 'data/house-price-data/train.csv'\n","home_data: pd.DataFrame = pd.read_csv(iowa_file_path)\n","\n","test_data_path = 'data/house-price-data/test.csv'\n","test_data: pd.DataFrame = pd.read_csv(test_data_path)"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["numerical features\n","['Id', 'LotFrontage', 'LotArea', 'OverallQual', 'OverallCond', 'YearBuilt', 'YearRemodAdd', 'MasVnrArea', 'BsmtFinSF1', 'BsmtFinSF2', 'BsmtUnfSF', 'TotalBsmtSF', '1stFlrSF', '2ndFlrSF', 'LowQualFinSF', 'GrLivArea', 'BsmtFullBath', 'BsmtHalfBath', 'FullBath', 'HalfBath', 'BedroomAbvGr', 'KitchenAbvGr', 'TotRmsAbvGrd', 'Fireplaces', 'GarageYrBlt', 'GarageCars', 'GarageArea', 'WoodDeckSF', 'OpenPorchSF', 'EnclosedPorch', '3SsnPorch', 'ScreenPorch', 'PoolArea', 'MiscVal', 'MoSold', 'YrSold']\n","categorical features\n","['MSZoning', 'Street', 'Alley', 'LotShape', 'LandContour', 'Utilities', 'LotConfig', 'LandSlope', 'Neighborhood', 'Condition1', 'Condition2', 'BldgType', 'HouseStyle', 'RoofStyle', 'RoofMatl', 'Exterior1st', 'Exterior2nd', 'MasVnrType', 'ExterQual', 'ExterCond', 'Foundation', 'BsmtQual', 'BsmtCond', 'BsmtExposure', 'BsmtFinType1', 'BsmtFinType2', 'Heating', 'HeatingQC', 'CentralAir', 'Electrical', 'KitchenQual', 'Functional', 'FireplaceQu', 'GarageType', 'GarageFinish', 'GarageQual', 'GarageCond', 'PavedDrive', 'PoolQC', 'Fence', 'MiscFeature', 'SaleType', 'SaleCondition', 'MSSubClass']\n"]}],"source":["# sort data into numeric and categoric variables\n","y = home_data['SalePrice']\n","home_data.drop(columns=['SalePrice'], inplace=True)\n","\n","numeric_features = [col for col in home_data.columns if is_numeric_dtype(home_data[col].dtype)]\n","categorical_features = [col for col in home_data.columns if is_string_dtype(home_data[col].dtype)]\n","# categorical values which appear as numbers\n","hidden_categorical = ['MSSubClass']\n","categorical_features.extend(hidden_categorical)\n","numeric_features = [n for n in numeric_features if (n not in hidden_categorical)]\n","print(\"numerical features\")\n","print(numeric_features)\n","print('categorical features')\n","print(categorical_features)"]},{"cell_type":"markdown","metadata":{},"source":["## Fill mising data, encode categorical features"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2022-02-08T20:47:40.302074Z","iopub.status.busy":"2022-02-08T20:47:40.301744Z","iopub.status.idle":"2022-02-08T20:47:42.530338Z","shell.execute_reply":"2022-02-08T20:47:42.529425Z","shell.execute_reply.started":"2022-02-08T20:47:40.302046Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["(1459, 322) (1460, 322)\n"]}],"source":["# get cols with missing data\n","cols_with_na = [c for c in home_data.columns if home_data[c].isna().any()]\n","\n","# print([1 if c else 0 for c in home_data[cols_with_na[1]].isna()])\n","# add indicator data was missing\n","for cna in cols_with_na:\n","    home_data[f'{cna}_was_missing'] = [1 if c else 0 for c in home_data[cols_with_na[1]].isna()]\n","    test_data[f'{cna}_was_missing'] = [1 if c else 0 for c in test_data[cols_with_na[1]].isna()]\n","    numeric_features.append(f'{cna}_was_missing')\n","\n","for nf in numeric_features:\n","    home_data[nf].fillna(home_data[nf].mean(), inplace=True)\n","    test_data[nf].fillna(test_data[nf].mean(), inplace=True)\n","\n","for cf in categorical_features:\n","    home_data[cf].fillna(home_data[cf].mode()[0], inplace=True)\n","    test_data[cf].fillna(test_data[cf].mode()[0], inplace=True)\n","\n","# onehotencoding for categorical features\n","ohe = OneHotEncoder(sparse=False, handle_unknown='ignore')\n","\n","cat_features_df = pd.DataFrame(ohe.fit_transform(home_data[categorical_features]), columns=ohe.get_feature_names_out())\n","\n","test_cat_features_df = pd.DataFrame(ohe.transform(test_data[categorical_features]), columns=ohe.get_feature_names_out())\n","\n","home_data = pd.concat([home_data[numeric_features], cat_features_df], axis=1)\n","test_data = pd.concat([test_data[numeric_features], test_cat_features_df], axis=1)\n","print(test_data.shape, home_data.shape)"]},{"cell_type":"markdown","metadata":{},"source":["### Feature selection"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Index(['Id', 'LotFrontage', 'LotArea', 'OverallQual', 'OverallCond',\n","       'YearBuilt', 'YearRemodAdd', 'MasVnrArea', 'BsmtFinSF1', 'BsmtFinSF2',\n","       ...\n","       'MSSubClass_60', 'MSSubClass_70', 'MSSubClass_75', 'MSSubClass_80',\n","       'MSSubClass_85', 'MSSubClass_90', 'MSSubClass_120', 'MSSubClass_160',\n","       'MSSubClass_180', 'MSSubClass_190'],\n","      dtype='object', length=322)\n"]}],"source":["features = home_data.columns\n","print(features)\n","# Select columns corresponding to features, and preview the data\n","X = home_data[features]\n","\n","# Split into validation and training data\n","train_X, val_X, train_y, val_y = train_test_split(X, y, test_size=0.4, random_state=1)"]},{"cell_type":"markdown","metadata":{},"source":["## Select model"]},{"cell_type":"code","execution_count":26,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Model: Gradient boost regressor; MAE:  17616\n","\n"]}],"source":["from sklearn.linear_model import LinearRegression, BayesianRidge \n","from lightgbm import LGBMRegressor\n","from xgboost.sklearn import XGBRegressor\n","from sklearn.ensemble import GradientBoostingRegressor\n","from sklearn.svm import SVR\n","\n","from sklearn.metrics import mean_absolute_error\n","\n","models = {# 'random forest': RandomForestRegressor(criterion='absolute_error'), \n","        # 'linear regression': LinearRegression(copy_X=True), \n","        # 'lgbm': LGBMRegressor(), \n","        # 'xgregressor': XGBRegressor(), \n","        'Gradient boost regressor': GradientBoostingRegressor(loss='absolute_error'),\n","        # 'SVR': SVR(),\n","        # 'bayes ridge': BayesianRidge(),\n","        }\n","\n","def get_mae(model):\n","    model.fit(train_X, train_y)\n","    model_predictions = model.predict(val_X)\n","    return mean_absolute_error(model_predictions, val_y)\n","\n","for model_name in models:\n","    model = models[model_name]\n","    mae = get_mae(model)\n","    print(f\"Model: {model_name}; MAE: {mae: .0f}\")\n","    print()\n","# Define a random forest model\n","# rf_model = RandomForestRegressor(random_state=1)\n","# rf_model.fit(train_X, train_y)\n","# rf_val_predictions = rf_model.predict(val_X)\n","# rf_val_mae = mean_absolute_error(rf_val_predictions, val_y)\n","\n","# relative_error = rf_val_mae/y.mean()\n","# print(f\"Validation MAE for Random Forest Model: {rf_val_mae: .0f}\")\n","# print(f\"Relative error: {relative_error}\")"]},{"cell_type":"markdown","metadata":{},"source":["## Hyperparam tuning"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["{'n_estimators': [10, 13, 19, 27, 37, 52, 73, 102, 143, 199], 'max_features': ['auto', 'sqrt'], 'max_depth': [1, 1, 2, 4, 7, 12, 21, 35, 59, 100], 'min_samples_split': [2, 5, 10], 'min_samples_leaf': [1, 2, 4], 'bootstrap': [True, False]}\n","[  1.           1.66810054   2.7825594    4.64158883   7.74263683\n","  12.91549665  21.5443469   35.93813664  59.94842503 100.        ]\n"]}],"source":["# hyperparams for random forest\n","\n","forest_random_grid = {'n_estimators': [int(x) for x in np.logspace(start=1, stop=2.3, num=10)],\n","               'max_features': ['auto', 'sqrt'],\n","               'max_depth': [int(x) for x in np.logspace(start=0, stop=2, num=10)],\n","               'min_samples_split': [2, 5, 10],\n","               'min_samples_leaf':[1, 2, 4],\n","               'bootstrap': [True, False]}\n","\n","print(forest_random_grid)"]},{"cell_type":"code","execution_count":31,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["{'n_estimators': [31, 42, 58, 79, 107, 146, 199, 271, 368, 501], 'max_depth': [1, 2, 3, 4, 5, 7, 10, 13, 18], 'subsample': [0.5, 0.75, 1], 'learning_rate': [0.5, 0.25, 0.1, 0.05], 'min_samples_split': array([0.01      , 0.06444444, 0.11888889, 0.17333333, 0.22777778,\n","       0.28222222, 0.33666667, 0.39111111, 0.44555556, 0.5       ])}\n"]}],"source":["# hyperparams for gradient boost regressor\n","# {'n_estimators':[200, 300, 400, 500, 600], 'max_depth':[2,3, 4, 5], 'subsample':[.5,.75,1], 'random_state':[1]}\n","GBR_random_grid = {'n_estimators': [int(x) for x in np.logspace(start=1.5, stop=2.7, num=10)],\n","                'max_depth': [1, 2, 3, 4, 5, 7, 10, 13, 18], \n","                'subsample': [0.5, 0.75, 1], \n","                'learning_rate': [0.5, 0.25, 0.1, 0.05], \n","                'min_samples_split': np.linspace(0.01, 0.5, 10, endpoint=True)}\n","print(GBR_random_grid)"]},{"cell_type":"code","execution_count":29,"metadata":{"execution":{"iopub.execute_input":"2022-02-08T20:47:42.532324Z","iopub.status.busy":"2022-02-08T20:47:42.531822Z","iopub.status.idle":"2022-02-08T20:47:43.705299Z","shell.execute_reply":"2022-02-08T20:47:43.704425Z","shell.execute_reply.started":"2022-02-08T20:47:42.53228Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Model: Gradient boost regressor\n","{'subsample': 0.75, 'n_estimators': 143, 'min_samples_split': 0.11888888888888888, 'max_depth': 5, 'learning_rate': 0.1}\n","-15790.059654179073\n"]}],"source":["from sklearn.model_selection import RandomizedSearchCV\n","from sklearn.metrics import mean_absolute_error, make_scorer\n","search_grids = {'random forest': forest_random_grid, \n","                'Gradient boost regressor': GBR_random_grid}\n","\n","best_params_for_model = {}\n","for model_name in models:\n","    model_to_optimise = models[model_name]\n","\n","    param_grid = search_grids[model_name]\n","    search = RandomizedSearchCV(estimator=model_to_optimise, \n","                                param_distributions=param_grid, \n","                                scoring=make_scorer(mean_absolute_error, greater_is_better=False), \n","                                n_iter=400, \n","                                n_jobs=-1, \n","                                cv=3)\n","\n","    search.fit(X, y)\n","    print(f'Model: {model_name}')\n","    print(search.best_params_)\n","    best_params_for_model[model_name] = search.best_params_\n","    print(search.best_score_)"]},{"cell_type":"markdown","metadata":{},"source":["## Fine param tuning with RandomSearch "]},{"cell_type":"code","execution_count":22,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["{'n_estimators': 199, 'min_samples_split': 5, 'min_samples_leaf': 2, 'max_features': 'sqrt', 'max_depth': 100, 'bootstrap': False}\n"]},{"name":"stderr","output_type":"stream","text":["/home/vasil/earth-analytics-parent/earth-analytics/conda-env/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:372: FitFailedWarning: \n","30 fits failed out of a total of 120.\n","The score on these train-test partitions for these parameters will be set to nan.\n","If these failures are not expected, you can try to debug them by setting error_score='raise'.\n","\n","Below are more details about the failures:\n","--------------------------------------------------------------------------------\n","21 fits failed with the following error:\n","Traceback (most recent call last):\n","  File \"/home/vasil/earth-analytics-parent/earth-analytics/conda-env/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n","    estimator.fit(X_train, y_train, **fit_params)\n","  File \"/home/vasil/earth-analytics-parent/earth-analytics/conda-env/lib/python3.9/site-packages/sklearn/ensemble/_forest.py\", line 450, in fit\n","    trees = Parallel(\n","  File \"/home/vasil/earth-analytics-parent/earth-analytics/conda-env/lib/python3.9/site-packages/joblib/parallel.py\", line 1043, in __call__\n","    if self.dispatch_one_batch(iterator):\n","  File \"/home/vasil/earth-analytics-parent/earth-analytics/conda-env/lib/python3.9/site-packages/joblib/parallel.py\", line 861, in dispatch_one_batch\n","    self._dispatch(tasks)\n","  File \"/home/vasil/earth-analytics-parent/earth-analytics/conda-env/lib/python3.9/site-packages/joblib/parallel.py\", line 779, in _dispatch\n","    job = self._backend.apply_async(batch, callback=cb)\n","  File \"/home/vasil/earth-analytics-parent/earth-analytics/conda-env/lib/python3.9/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n","    result = ImmediateResult(func)\n","  File \"/home/vasil/earth-analytics-parent/earth-analytics/conda-env/lib/python3.9/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n","    self.results = batch()\n","  File \"/home/vasil/earth-analytics-parent/earth-analytics/conda-env/lib/python3.9/site-packages/joblib/parallel.py\", line 262, in __call__\n","    return [func(*args, **kwargs)\n","  File \"/home/vasil/earth-analytics-parent/earth-analytics/conda-env/lib/python3.9/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n","    return [func(*args, **kwargs)\n","  File \"/home/vasil/earth-analytics-parent/earth-analytics/conda-env/lib/python3.9/site-packages/sklearn/utils/fixes.py\", line 216, in __call__\n","    return self.function(*args, **kwargs)\n","  File \"/home/vasil/earth-analytics-parent/earth-analytics/conda-env/lib/python3.9/site-packages/sklearn/ensemble/_forest.py\", line 187, in _parallel_build_trees\n","    tree.fit(X, y, sample_weight=sample_weight, check_input=False)\n","  File \"/home/vasil/earth-analytics-parent/earth-analytics/conda-env/lib/python3.9/site-packages/sklearn/tree/_classes.py\", line 1315, in fit\n","    super().fit(\n","  File \"/home/vasil/earth-analytics-parent/earth-analytics/conda-env/lib/python3.9/site-packages/sklearn/tree/_classes.py\", line 235, in fit\n","    raise ValueError(\n","ValueError: min_samples_leaf must be at least 1 or in (0, 0.5], got 0\n","\n","--------------------------------------------------------------------------------\n","9 fits failed with the following error:\n","Traceback (most recent call last):\n","  File \"/home/vasil/earth-analytics-parent/earth-analytics/conda-env/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n","    estimator.fit(X_train, y_train, **fit_params)\n","  File \"/home/vasil/earth-analytics-parent/earth-analytics/conda-env/lib/python3.9/site-packages/sklearn/ensemble/_forest.py\", line 450, in fit\n","    trees = Parallel(\n","  File \"/home/vasil/earth-analytics-parent/earth-analytics/conda-env/lib/python3.9/site-packages/joblib/parallel.py\", line 1043, in __call__\n","    if self.dispatch_one_batch(iterator):\n","  File \"/home/vasil/earth-analytics-parent/earth-analytics/conda-env/lib/python3.9/site-packages/joblib/parallel.py\", line 861, in dispatch_one_batch\n","    self._dispatch(tasks)\n","  File \"/home/vasil/earth-analytics-parent/earth-analytics/conda-env/lib/python3.9/site-packages/joblib/parallel.py\", line 779, in _dispatch\n","    job = self._backend.apply_async(batch, callback=cb)\n","  File \"/home/vasil/earth-analytics-parent/earth-analytics/conda-env/lib/python3.9/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n","    result = ImmediateResult(func)\n","  File \"/home/vasil/earth-analytics-parent/earth-analytics/conda-env/lib/python3.9/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n","    self.results = batch()\n","  File \"/home/vasil/earth-analytics-parent/earth-analytics/conda-env/lib/python3.9/site-packages/joblib/parallel.py\", line 262, in __call__\n","    return [func(*args, **kwargs)\n","  File \"/home/vasil/earth-analytics-parent/earth-analytics/conda-env/lib/python3.9/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n","    return [func(*args, **kwargs)\n","  File \"/home/vasil/earth-analytics-parent/earth-analytics/conda-env/lib/python3.9/site-packages/sklearn/utils/fixes.py\", line 216, in __call__\n","    return self.function(*args, **kwargs)\n","  File \"/home/vasil/earth-analytics-parent/earth-analytics/conda-env/lib/python3.9/site-packages/sklearn/ensemble/_forest.py\", line 187, in _parallel_build_trees\n","    tree.fit(X, y, sample_weight=sample_weight, check_input=False)\n","  File \"/home/vasil/earth-analytics-parent/earth-analytics/conda-env/lib/python3.9/site-packages/sklearn/tree/_classes.py\", line 1315, in fit\n","    super().fit(\n","  File \"/home/vasil/earth-analytics-parent/earth-analytics/conda-env/lib/python3.9/site-packages/sklearn/tree/_classes.py\", line 250, in fit\n","    raise ValueError(\n","ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n","\n","  warnings.warn(some_fits_failed_message, FitFailedWarning)\n","/home/vasil/earth-analytics-parent/earth-analytics/conda-env/lib/python3.9/site-packages/sklearn/model_selection/_search.py:969: UserWarning: One or more of the test scores are non-finite: [-17158.06901538 -19522.64189772 -18289.56142803 -18623.12887344\n"," -18815.39357331 -19637.80603263 -17312.85816931             nan\n"," -17793.51919063 -18847.44088206             nan -18955.79844914\n"," -19691.56746473 -17927.38624194 -17541.61593184             nan\n"," -18508.57849899 -17917.22653089 -17933.67386166 -18889.60593285\n","             nan             nan -19027.87303208 -19517.30715753\n"," -18217.49484553 -18517.82191932             nan             nan\n","             nan -19464.65673179 -18213.6747111  -18513.86277972\n"," -17219.61857166             nan -18432.56885601 -18548.98958873\n"," -18748.27652381 -19690.65887742 -19644.56574473             nan]\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["Model: random forest\n","{'n_estimators': 135, 'min_samples_split': 3, 'min_samples_leaf': 1, 'max_features': 'sqrt', 'max_depth': 113, 'bootstrap': False}\n","-17158.069015377303\n","{'subsample': 1, 'n_estimators': 199, 'min_samples_split': 0.3911111111111111, 'max_depth': 10, 'learning_rate': 0.05}\n"]},{"name":"stderr","output_type":"stream","text":["/home/vasil/earth-analytics-parent/earth-analytics/conda-env/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:372: FitFailedWarning: \n","84 fits failed out of a total of 120.\n","The score on these train-test partitions for these parameters will be set to nan.\n","If these failures are not expected, you can try to debug them by setting error_score='raise'.\n","\n","Below are more details about the failures:\n","--------------------------------------------------------------------------------\n","39 fits failed with the following error:\n","Traceback (most recent call last):\n","  File \"/home/vasil/earth-analytics-parent/earth-analytics/conda-env/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n","    estimator.fit(X_train, y_train, **fit_params)\n","  File \"/home/vasil/earth-analytics-parent/earth-analytics/conda-env/lib/python3.9/site-packages/sklearn/ensemble/_gb.py\", line 525, in fit\n","    self._check_params()\n","  File \"/home/vasil/earth-analytics-parent/earth-analytics/conda-env/lib/python3.9/site-packages/sklearn/ensemble/_gb.py\", line 317, in _check_params\n","    raise ValueError(\"subsample must be in (0,1] but was %r\" % self.subsample)\n","ValueError: subsample must be in (0,1] but was 3\n","\n","--------------------------------------------------------------------------------\n","27 fits failed with the following error:\n","Traceback (most recent call last):\n","  File \"/home/vasil/earth-analytics-parent/earth-analytics/conda-env/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n","    estimator.fit(X_train, y_train, **fit_params)\n","  File \"/home/vasil/earth-analytics-parent/earth-analytics/conda-env/lib/python3.9/site-packages/sklearn/ensemble/_gb.py\", line 525, in fit\n","    self._check_params()\n","  File \"/home/vasil/earth-analytics-parent/earth-analytics/conda-env/lib/python3.9/site-packages/sklearn/ensemble/_gb.py\", line 317, in _check_params\n","    raise ValueError(\"subsample must be in (0,1] but was %r\" % self.subsample)\n","ValueError: subsample must be in (0,1] but was 2\n","\n","--------------------------------------------------------------------------------\n","18 fits failed with the following error:\n","Traceback (most recent call last):\n","  File \"/home/vasil/earth-analytics-parent/earth-analytics/conda-env/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n","    estimator.fit(X_train, y_train, **fit_params)\n","  File \"/home/vasil/earth-analytics-parent/earth-analytics/conda-env/lib/python3.9/site-packages/sklearn/ensemble/_gb.py\", line 525, in fit\n","    self._check_params()\n","  File \"/home/vasil/earth-analytics-parent/earth-analytics/conda-env/lib/python3.9/site-packages/sklearn/ensemble/_gb.py\", line 317, in _check_params\n","    raise ValueError(\"subsample must be in (0,1] but was %r\" % self.subsample)\n","ValueError: subsample must be in (0,1] but was 0\n","\n","  warnings.warn(some_fits_failed_message, FitFailedWarning)\n","/home/vasil/earth-analytics-parent/earth-analytics/conda-env/lib/python3.9/site-packages/sklearn/model_selection/_search.py:969: UserWarning: One or more of the test scores are non-finite: [-19000.9104178              nan             nan -16704.15662975\n","             nan             nan -16045.96189578             nan\n"," -21558.96696909 -16885.50536872 -16572.32595134             nan\n","             nan -16765.60165093             nan -17050.30709759\n","             nan             nan             nan -16690.77143966\n","             nan             nan -29999.81436828 -33139.11930903\n","             nan             nan             nan             nan\n","             nan -17223.21917021             nan             nan\n","             nan             nan             nan             nan\n","             nan             nan             nan             nan]\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["Model: Gradient boost regressor\n","{'subsample': 1, 'n_estimators': 377, 'min_samples_split': 0.3911111111111111, 'max_depth': 18, 'learning_rate': 0.056823183319286236}\n","-16045.961895781174\n"]}],"source":["\n","for model_name in models:\n","    best_params = best_params_for_model[model_name]\n","    print(best_params)\n","    # make new tighter grid range for each model\n","    grid_range = {}\n","    for param_name in best_params:\n","        if type(best_params[param_name]) == int:\n","            grid_range[param_name] = list(set(map(int, np.logspace(start=np.log10(best_params[param_name]) - 0.5, \n","                                                stop=np.log10(best_params[param_name]) + 0.5, \n","                                                num=10))))\n","        elif type(best_params[param_name]) == float:\n","            grid_range[param_name] = np.logspace(start=np.log10(best_params[param_name]) - 0.5, \n","                                                stop=np.log10(best_params[param_name]) + 0.5, \n","                                                num=10)\n","        else:\n","            grid_range[param_name] = [best_params[param_name]]\n","\n","    search = RandomizedSearchCV(estimator=models[model_name], \n","                                param_distributions=grid_range, \n","                                scoring=make_scorer(mean_absolute_error, greater_is_better=False), \n","                                n_iter=400, \n","                                n_jobs=-1, \n","                                cv=3)\n","\n","    search.fit(X, y)\n","    print(f'Model: {model_name}')\n","    print(search.best_params_)\n","    print(search.best_score_)"]},{"cell_type":"code","execution_count":23,"metadata":{},"outputs":[{"data":{"text/plain":["GradientBoostingRegressor(learning_rate=0.056, loss='absolute_error',\n","                          max_depth=18, min_samples_split=0.39,\n","                          n_estimators=377, subsample=1)"]},"execution_count":23,"metadata":{},"output_type":"execute_result"}],"source":["full_model = GradientBoostingRegressor(max_depth=18, n_estimators=377, subsample=1, min_samples_split=0.39, learning_rate=0.056, loss='absolute_error')\n","full_model.fit(X, y)"]},{"cell_type":"markdown","metadata":{},"source":["Now, read the file of \"test\" data, and apply your model to make predictions."]},{"cell_type":"code","execution_count":24,"metadata":{"execution":{"iopub.execute_input":"2022-02-08T20:47:43.707891Z","iopub.status.busy":"2022-02-08T20:47:43.707397Z","iopub.status.idle":"2022-02-08T20:47:43.781974Z","shell.execute_reply":"2022-02-08T20:47:43.780201Z","shell.execute_reply.started":"2022-02-08T20:47:43.707847Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["[127785.32409969 160805.35456975 187761.69093958 ... 176332.92193729\n"," 118776.8123949  236648.81353804]\n","<class 'numpy.ndarray'> 1459\n"]}],"source":["# path to file you will use for predictions\n","# test_data_path = '../input/test.csv'\n","\n","# # read test data file using pandas\n","# test_data = pd.read_csv(test_data_path)\n","\n","# # create test_X which comes from test_data but includes only the columns you used for prediction.\n","# # The list of columns is stored in a variable called features\n","test_X = test_data[features]\n","\n","# # make predictions which we will submit. \n","test_preds = full_model.predict(test_X)\n","print(test_preds)\n","print(type(test_preds), len(test_preds))"]},{"cell_type":"markdown","metadata":{},"source":["Before submitting, run a check to make sure your `test_preds` have the right format."]},{"cell_type":"markdown","metadata":{},"source":["# Generate a submission\n","\n","Run the code cell below to generate a CSV file with your predictions that you can use to submit to the competition."]},{"cell_type":"code","execution_count":25,"metadata":{"execution":{"iopub.execute_input":"2022-02-08T20:47:43.794601Z","iopub.status.busy":"2022-02-08T20:47:43.793825Z","iopub.status.idle":"2022-02-08T20:47:43.812959Z","shell.execute_reply":"2022-02-08T20:47:43.81213Z","shell.execute_reply.started":"2022-02-08T20:47:43.794547Z"},"trusted":true},"outputs":[],"source":["# Run the code to save predictions in the format used for competition scoring\n","\n","output = pd.DataFrame({'Id': test_data.Id,\n","                       'SalePrice': test_preds})\n","output.to_csv('code/house-prices-competition/submission_grad_boost_best_tuning.csv', index=False)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.7"}},"nbformat":4,"nbformat_minor":4}
